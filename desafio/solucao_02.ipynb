{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importa bibliotecas `pandas` e `numpy`.  \n",
    "2. Define semente aleatória para reprodutibilidade.  \n",
    "3. Cria base fictícia com 1000 transações.  \n",
    "4. Gera valores aleatórios para transações, taxas e isenções.  \n",
    "5. Corrige taxas para zero quando há isenção aplicada.  \n",
    "6. Introduz 5 erros simulando cobranças indevidas em isentos.  \n",
    "7. Insere 5 anomalias com taxas muito altas em transações não isentas.  \n",
    "8. Cria DataFrame com os dados simulados.  \n",
    "9. Salva os dados em um arquivo CSV.  \n",
    "10. Exibe mensagem de sucesso após gerar o arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Criar base de dados fictícia\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    \"ID_Transação\": range(1, 1001),\n",
    "    \"Valor_Transação\": np.random.uniform(50, 500, 1000).round(2),\n",
    "    \"Taxa_Cobrada\": np.random.uniform(1, 15, 1000).round(2),\n",
    "    \"Isenção_Aplicada\": np.random.choice([\"Sim\", \"Não\"], 1000, p=[0.2, 0.8])\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Simular erros e anomalias\n",
    "# 2.1. Corrigir isenções (taxa = 0) e adicionar erros de cobrança\n",
    "df.loc[df[\"Isenção_Aplicada\"] == \"Sim\", \"Taxa_Cobrada\"] = 0\n",
    "erros_isenção = np.random.choice(df[df[\"Isenção_Aplicada\"] == \"Sim\"].index, 5, replace=False)\n",
    "df.loc[erros_isenção, \"Taxa_Cobrada\"] = np.random.uniform(1, 10, 5).round(2)\n",
    "\n",
    "# 2.2. GERAR ANOMALIAS (outliers) em transações NÃO isentas\n",
    "anomalias = np.random.choice(df[df[\"Isenção_Aplicada\"] == \"Não\"].index, 5, replace=False)\n",
    "df.loc[anomalias, \"Taxa_Cobrada\"] = np.random.choice([45, 46, 47, 48, 49], 5)  # Valores extremos\n",
    "\n",
    "# 3. Salvar em CSV (arquivo será criado no mesmo diretório do script)\n",
    "df.to_csv(\"transacoes_paysmart.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ Arquivo 'transacoes_paysmart.csv' gerado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importa bibliotecas para manipulação de dados, detecção de anomalias (`IsolationForest`), padronização (`StandardScaler`), salvamento de modelos (`joblib`) e controle de tempo.  \n",
    "2. Define constantes com os nomes do arquivo de dados (`transacoes_paysmart.csv`) e do modelo salvo (`modelo_cobrancas.pkl`).  \n",
    "3. Prepara o ambiente para carregar dados, treinar ou usar modelo de machine learning em cobrança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Nome do arquivo (coloque na mesma pasta do script)\n",
    "ARQUIVO_DADOS = \"transacoes_paysmart.csv\"  \n",
    "MODELO_PATH = \"modelo_cobrancas.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lê os dados do arquivo CSV definido (`ARQUIVO_DADOS`).  \n",
    "2. Cria a variável `Taxa_Relativa` e seleciona colunas relevantes para o modelo.  \n",
    "3. Normaliza os dados com `StandardScaler` e treina um `IsolationForest` para detectar anomalias.  \n",
    "4. Salva o modelo e o scaler em um arquivo (`MODELO_PATH`) com `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelo():\n",
    "    \"\"\"Treina o modelo com os dados disponíveis\"\"\"\n",
    "    df = pd.read_csv(ARQUIVO_DADOS)\n",
    "    \n",
    "    # Preparação dos dados\n",
    "    df['Taxa_Relativa'] = df['Taxa_Cobrada'] / df['Valor_Transação']\n",
    "    features = ['Valor_Transação', 'Taxa_Cobrada', 'Taxa_Relativa']\n",
    "    X = df[features]\n",
    "    \n",
    "    # Normalização e modelo\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    model = IsolationForest(contamination=0.005, random_state=42).fit(scaler.transform(X))\n",
    "    \n",
    "    # Salva modelo e scaler juntos\n",
    "    joblib.dump({'model': model, 'scaler': scaler}, MODELO_PATH)\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Verifica se o arquivo do modelo (`MODELO_PATH`) existe.  \n",
    "2. Tenta carregar o modelo e o scaler com `joblib`.  \n",
    "3. Se carregar com sucesso, retorna o modelo e o scaler salvos.  \n",
    "4. Em caso de erro ou ausência do arquivo, treina e retorna um novo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_modelo():\n",
    "    \"\"\"Carrega o modelo se existir, ou treina um novo\"\"\"\n",
    "    if os.path.exists(MODELO_PATH):\n",
    "        try:\n",
    "            dados = joblib.load(MODELO_PATH)\n",
    "            print(\"✅ Modelo carregado\")\n",
    "            return dados['model'], dados['scaler']\n",
    "        except:\n",
    "            print(\"⚠️ Erro ao carregar, treinando novo...\")\n",
    "    return treinar_modelo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carrega ou treina o modelo e o scaler com `carregar_modelo()`.  \n",
    "2. Lê os dados do arquivo CSV com transações.  \n",
    "3. Calcula a coluna `Taxa_Relativa` para análise.  \n",
    "4. Padroniza os dados com o scaler carregado.  \n",
    "5. Usa o modelo `IsolationForest` para identificar anomalias.  \n",
    "6. Detecta erros de isenção com base nas regras de cobrança.  \n",
    "7. Filtra as transações com anomalias ou erros.  \n",
    "8. Se houver problemas, salva um relatório em CSV com data e hora.  \n",
    "9. Imprime mensagem com número de alertas ou confirmação de normalidade.  \n",
    "10. Executa a função `monitorar()` em loop, com pausa de 30 segundos entre execuções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitorar():\n",
    "    \"\"\"Executa a detecção de anomalias\"\"\"\n",
    "    model, scaler = carregar_modelo()\n",
    "    df = pd.read_csv(ARQUIVO_DADOS)\n",
    "    \n",
    "    # Prepara e classifica os dados\n",
    "    df['Taxa_Relativa'] = df['Taxa_Cobrada'] / df['Valor_Transação']\n",
    "    X = scaler.transform(df[['Valor_Transação', 'Taxa_Cobrada', 'Taxa_Relativa']])\n",
    "    df['Anomalia'] = np.where(model.predict(X) == -1, 1, 0)\n",
    "    df['Erro_Isencao'] = (df['Isenção_Aplicada'] == \"Sim\") & (df['Taxa_Cobrada'] > 0)\n",
    "    \n",
    "    # Filtra problemas\n",
    "    problemas = df[df['Anomalia'] | df['Erro_Isencao']]\n",
    "    if not problemas.empty:\n",
    "        nome_relatorio = f\"alertas_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "        problemas.to_csv(nome_relatorio, index=False)\n",
    "        print(f\"⚠️ {len(problemas)} alertas em {nome_relatorio}\")\n",
    "    else:\n",
    "        print(\"✅ Nenhum problema detectado\")\n",
    "\n",
    "# Executa a cada hora\n",
    "while True:\n",
    "    monitorar()\n",
    "    time.sleep(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
